<!---
Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

# Models that are / aren't supported by ü§ó Exporters

Only models that have a `ModelNameCoreMLConfig` object are currently supported.

If a model is not supported, this is either because there is some problem with the actual conversion process, or because we simply did not get around to writing a `CoreMLConfig` object for it.

## Supported models

Legend:

- ‚úÖ = fully supported
- üòì = works but with hacks
- ‚ö†Ô∏è = partially supported (for example no "with past" version)
- ‚ùå = errors during conversion
- ‚ûñ = not supported
- ? = unknown

### Text Models

**BERT**

- ‚úÖ BertModel
- ‚ûñ BertForPreTraining
- ‚úÖ BertForMaskedLM
- ‚úÖ BertForMultipleChoice
- ‚úÖ BertForNextSentencePrediction
- ‚úÖ BertForQuestionAnswering
- ‚úÖ BertForSequenceClassification
- ‚úÖ BertForTokenClassification
- üòì BertLMHeadModel: Appears to work OK when using `use_legacy_format`. However, when using MIL the conversion succeeds but the model may not actually run. It works OK with `use_past=False` or flexible sequence lengths, but blows up with `use_past=True` (Core ML takes forever to load the model, allocates 100+ GB of RAM and eventually crashes).

**BigBird**

- ? BigBirdModel
- ‚ûñ BigBirdForPreTraining
- üòì BigBirdForCausalLM: Appears to work OK when using `use_legacy_format`. However, when using MIL the conversion succeeds but the model may not actually run. It works OK with `use_past=False` or flexible sequence lengths, but blows up with `use_past=True` (Core ML takes forever to load the model, allocates 100+ GB of RAM and eventually crashes).
- ? BigBirdForMaskedLM
- ? BigBirdForMultipleChoice
- ? BigBirdForQuestionAnswering
- ? BigBirdForSequenceClassification
- ? BigBirdForTokenClassification

**CTRL**

- ‚úÖ CTRLModel
- ‚úÖ CTRLLMHeadModel
- ‚úÖ CTRLForSequenceClassification

**DistilBERT**

- ‚úÖ DistilBertModel
- ‚úÖ DistilBertForMaskedLM
- ‚úÖ DistilBertForMultipleChoice
- ‚úÖ DistilBertForQuestionAnswering
- ‚úÖ DistilBertForSequenceClassification
- ‚úÖ DistilBertForTokenClassification


**ERNIE**

- ? ErnieModel
- ‚ûñ ErnieForPreTraining
- üòì ErnieForCausalLM: Appears to work OK when using `use_legacy_format`. However, when using MIL the conversion succeeds but the model may not actually run. It works OK with `use_past=False` or flexible sequence lengths, but blows up with `use_past=True` (Core ML takes forever to load the model, allocates 100+ GB of RAM and eventually crashes).
- ? ErnieForMaskedLM
- ? ErnieForMultipleChoice
- ? ErnieForNextSentencePrediction
- ? ErnieForQuestionAnswering
- ? ErnieForSequenceClassification
- ? ErnieForTokenClassification

**GPT2 / DistilGPT2**

Needs to be exported with `use_legacy_format=True`. Does not work with flexible sequence length and therefore does not support `use_past`.

- ‚úÖ GPT2Model
- ‚ûñ GPT2DoubleHeadsModel
- ‚úÖ GPT2ForSequenceClassification
- ‚úÖ GPT2ForTokenClassification
- ‚ö†Ô∏è GPT2LMHeadModel (no `use_past`)

**MobileBERT**

- ‚úÖ MobileBertModel
- ‚ûñ MobileBertForPreTraining
- ‚úÖ MobileBertForMaskedLM
- ‚úÖ MobileBertForMultipleChoice
- ‚úÖ MobileBertForNextSentencePrediction
- ‚úÖ MobileBertForQuestionAnswering
- ‚úÖ MobileBertForSequenceClassification
- ‚úÖ MobileBertForTokenClassification

**SqueezeBERT**

- ‚úÖ SqueezeBertModel
- ‚úÖ SqueezeBertForMaskedLM
- ‚úÖ SqueezeBertForMultipleChoice
- ‚úÖ SqueezeBertForQuestionAnswering
- ‚úÖ SqueezeBertForSequenceClassification
- ‚úÖ SqueezeBertForTokenClassification

### Vision Models

**BEiT**

- ‚úÖ BeitModel
- ‚úÖ BeitForImageClassification
- ‚úÖ BeitForSemanticSegmentation
- ‚úÖ BeitForMaskedImageModeling. Note: this model does not work with AutoModelForMaskedImageModeling and therefore the conversion script cannot load it, but converting from Python is supported.

**ConvNeXT**

- ‚úÖ ConvNextModel
- ‚úÖ ConvNextForImageClassification

**CvT**

- ‚úÖ CvtModel
- ‚úÖ CvtForImageClassification

**LeViT**

- ‚úÖ LevitModel
- ‚úÖ LevitForImageClassification
- ‚ûñ LevitForImageClassificationWithTeacher

**MobileViT**

- ‚úÖ MobileViTModel
- ‚úÖ MobileViTForImageClassification
- ‚úÖ MobileViTForSemanticSegmentation

**SegFormer**

- ‚úÖ SegformerModel
- ‚úÖ SegformerForImageClassification
- ‚úÖ SegformerForSemanticSegmentation

**Vision Transformer (ViT)**

- ‚úÖ ViTModel
- ‚úÖ ViTForMaskedImageModeling
- ‚úÖ ViTForImageClassification

**YOLOS**

- ‚úÖ YolosModel
- ‚úÖ YolosForObjectDetection

### Audio Models

None

### Multimodal Models

None

## Models that currently don't work

The following models are known to give errors when attempting conversion to Core ML format, or simply have not been tried yet.

### Text Models

ALBERT

**BART**

- ? BartModel
- ‚ùå BartForCausalLM: Conversion succeeds, but "Error computing NN outputs".
- ‚ùå BartForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.
- ? BartForQuestionAnswering
- ? BartForSequenceClassification

BARThez

BARTpho

BertGeneration

BertJapanese

Bertweet

**BigBirdPegasus**

- ‚ùå BigBirdPegasusForCausalLM: Core ML error "Error computing NN outputs"
- ‚ùå BigBirdPegasusForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**Blenderbot**

- ‚ùå BlenderbotForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**Blenderbot Small**

- ‚ùå BlenderbotSmallForConditionalGeneration:  Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**BLOOM** [TODO verify] Conversion error on a slicing operation.

BORT

ByT5

CamemBERT

CANINE

**CodeGen** [TODO verify] Conversion error on einsum.

ConvBERT

CPM

DeBERTa

DeBERTa-v2

DialoGPT

DPR

**ELECTRA**

- ‚ùå ElectraForCausalLM: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op. Also, `coreml_config.values_override` doesn't work to set `use_cache` to True for this model.

Encoder Decoder Models

ESM

FlauBERT

FNet

**FSMT**

- ‚ùå FSMTForConditionalGeneration. Encoder converts OK. For decoder, `Wrapper` outputs wrong size logits tensor; goes wrong somewhere in hidden states output from decoder when `return_dict=False`?

Funnel Transformer

GPT

**GPT Neo**. [TODO verify] Gives no errors during conversion but predicts wrong results, or NaN when `use_legacy_format=True`.

- GPTNeoModel
- GPTNeoForCausalLM
- GPTNeoForSequenceClassification

GPT NeoX

GPT NeoX Japanese

GPT-J

HerBERT

I-BERT

LayoutLM

**LED**

- ‚ùå LEDForConditionalGeneration: JIT trace fails with the error:

```python
RuntimeError: 0INTERNAL ASSERT FAILED at "/Users/distiller/project/pytorch/torch/csrc/jit/ir/alias_analysis.cpp":607, please report a bug to PyTorch. We don't have an op for aten::constant_pad_nd but it isn't a special case.  Argument types: Tensor, int[], bool,
```

LiLT

Longformer

**LongT5**

- ‚ùå LongT5ForConditionalGeneration: Conversion error:

```python
ValueError: In op, of type not_equal, named 133, the named input `y` must have the same data type as the named input `x`. However, y has dtype fp32 whereas x has dtype int32.
```

LUKE

**M2M100**

- ‚ùå M2M100ForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**MarianMT**

- ‚ùå MarianMTModel: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

MarkupLM

MBart and MBart-50

MegatronBERT

MegatronGPT2

mLUKE

MPNet

**MT5**

- ‚ùå MT5ForConditionalGeneration: Converter error "User defined pattern has more than one final operation"

**MVP**

- ‚ùå MvpForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**NEZHA** [TODO verify] Conversion error on a slicing operation.

NLLB

Nystr√∂mformer

**OPT** [TODO verify] Conversion error on a slicing operation.

**Pegasus**

- ‚ùå PegasusForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**PEGASUS-X**

- ‚ùå PegasusXForConditionalGeneration: "AttributeError: 'list' object has no attribute 'val'" in `pad` op. Maybe: needs `remainder` op (added recently in coremltools dev version).

PhoBERT

**PLBart**

- ‚ùå PLBartForConditionalGeneration: Encoder converts OK (tested only `use_past=False`). Decoder gives "Error computing NN outputs" with flexible sequence length.

**ProphetNet**

- ‚ùå ProphetNetForConditionalGeneration. Conversion error:

```python
ValueError: Op "input.3" (op_type: clip) Input x="position_ids" expects tensor or scalar of dtype from type domain ['fp16', 'fp32'] but got tensor[1,is4273,int32]
```

QDQBert

RAG

REALM

**Reformer**

- ‚ùå ReformerModelWithLMHead: does not have `past_key_values` but `past_buckets_states`

**RemBERT**

- ‚ùå RemBertForCausalLM: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op. Also error adding a constant value to the MIL graph?

RetriBERT

**RoBERTa**

- ‚ùå RobertaForCausalLM: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op.

**RoFormer**

- ‚ùå RoFormerForCausalLM: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op. Also error adding a constant value to the MIL graph?

**Splinter**

- ‚ùå SplinterModel: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op. Also error adding a constant value to the MIL graph?

**T5**

- ‚ùå T5ForConditionalGeneration: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op.

T5v1.1

TAPAS

TAPEX

Transformer XL

UL2

**XGLM** [TODO verify] Conversion error on a slicing operation.

XLM

**XLM-ProphetNet**

- XLMProphetNetForConditionalGeneration: Conversion error:

```python
ValueError: Op "input.3" (op_type: clip) Input x="position_ids" expects tensor or scalar of dtype from type domain ['fp16', 'fp32'] but got tensor[1,is4506,int32]
```

XLM-RoBERTa

XLM-RoBERTa-XL

**XLNet** [TODO verify] Conversion error.

YOSO

### Vision Models

Conditional DETR

Deformable DETR

DeiT

**DETR** [TODO verify] The conversion completes without errors but the Core ML compiler cannot load the model. "Invalid operation output name: got 'tensor' when expecting token of type 'ID'"

DiT

DPT

GLPN

ImageGPT

MaskFormer

PoolFormer

RegNet

ResNet

**Swin Transformer** [TODO verify] The PyTorch graph contains unsupported operations: remainder, roll, adaptive_avg_pool1d. (Some of these may be supported in latest dev version.)

Swin Transformer V2

VAN

VideoMAE

ViTMAE

ViTMSN

### Audio Models

**Hubert** [TODO verify] Unsupported op for `nn.GroupNorm` (should be possible to solve), invalid broadcasting operations (will be harder to solve), and most likely additional issues.

MCTCT

**SEW** [TODO verify] Unsupported op for `nn.GroupNorm` (should be possible to solve), invalid broadcasting operations (will be harder to solve), and most likely additional issues.

SEW-D

**Speech2Text** [TODO verify] The "glu" op is not supported by coremltools. Should be possible to solve by defining a `@register_torch_op` function. (Update: should be supported in dev version now.)

Speech2Text2

**UniSpeech** [TODO verify] Missing op for `_weight_norm` (possible to work around), also same Core ML compiler error as DETR.

UniSpeech-SAT

**Wav2Vec2** [TODO verify] Unsupported op for `nn.GroupNorm` (should be possible to solve), invalid broadcasting operations (will be harder to solve), and most likely additional issues.

Wav2Vec2-Conformer

Wav2Vec2Phoneme

**WavLM** [TODO verify] Missing ops for `_weight_norm`, `add_`, `full_like`.

Whisper

XLS-R

XLSR-Wav2Vec2

### Multimodal Models

CLIP

**Data2Vec**

- ‚ùå Data2VecTextForCausalLM: "AttributeError: 'list' object has no attribute 'val'" in `repeat` op

- Data2VecAudio: [TODO verify] The conversion completes without errors but the Core ML compiler cannot load the model.

Donut

FLAVA

**GroupViT** [TODO verify] Conversion issue with `scatter_along_axis` operation.

LayoutLMV2

LayoutLMV3

LayoutXLM

LXMERT

OWL-ViT

Perceiver

Speech Encoder Decoder Models

TrOCR

ViLT

Vision Encoder Decoder Models

Vision Text Dual Encoder

VisualBERT

X-CLIP
